services:
  diagnostic-agent:
    build: 
      context: .
      dockerfile: Dockerfile.fast
      # Enable BuildKit for faster, more efficient builds
      cache_from:
        - python:3.11-slim
      # Use build arguments to improve caching
      args:
        BUILDKIT_INLINE_CACHE: 1
    container_name: diagnostic-journalist-symbiote
    env_file:
      - .env
    ports:
      - "0.0.0.0:5000:5000"
    environment:
      - PYTHONUNBUFFERED=1
      - FLASK_ENV=development
      - PYTHONDONTWRITEBYTECODE=1
      - PYTHONPATH=/app
      - DOCKER_BUILDKIT=1
      - COMPOSE_DOCKER_CLI_BUILD=1
      - HOST_ETC_PATH=/host/etc
      # Symbiote mode: All models run on dev machine (no remote delegation)
      - SYMBIOTE_MODE=true
      - DEV_MACHINE_MAC=98:48:27:C6:51:05
      - DEV_MACHINE_IP=127.0.0.1  # Local since everything runs on dev machine
      - DEV_MACHINE_PORT=2222
      - DEV_MACHINE_USER=vince
      - SSH_TIMEOUT=2  # Faster timeout for local connections
      - SSH_MAX_RETRIES=1  # Fewer retries for local
      - SSH_RETRY_DELAY=5
      - BRIDGE_CHECK_INTERVAL=60  # More frequent checks for dev
      - WAKE_ON_LAN_ENABLED=false  # Not needed in symbiote mode
      - TINYLLAMA_MODEL_PATH=/app/models/tinyllama.gguf
      - HOST_PROC_PATH=/host/proc
    volumes:
      # Persist agent memory across container restarts
      - agent_memory:/app/agent_memory
      # Mount logs for external monitoring if needed
      - ./logs:/app/logs
      # Mount models directory for TinyLlama and other local models
      - ./models:/app/models
      # Cache for sentence transformer models to speed up restarts
      - model_cache:/home/agent/.cache
      # Mount host network and system info for diagnostics (Windows/WSL paths)
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /etc:/host/etc:ro
      # Add Docker socket for container monitoring (with proper permissions)
      - /var/run/docker.sock:/var/run/docker.sock:rw
    command: ["python3", "web_agent.py"]
    restart: unless-stopped
    # Use bridge network with port mapping for better isolation
    privileged: false
    cap_add:
      - NET_ADMIN
      - NET_RAW
      - SYS_ADMIN
    networks:
      - diagnostic-net
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s  # Faster startup for dev machine
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    # No resource limits for dev machine - use full power
    security_opt:
      - no-new-privileges:true
    tmpfs:
      - /tmp
      - /var/tmp
      - /home/agent/.cache/huggingface
      # Allow writing to Python cache
      - /home/agent/.cache/pip:rw

  # Optional: Include OpenHermes inference server for local LLM fallback
  openhermes-server:
    build:
      context: ./inference-server
      dockerfile: Dockerfile
    container_name: openhermes-symbiote
    ports:
      - "11434:11434"
    volumes:
      - ollama-data:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0
    restart: unless-stopped
    networks:
      - diagnostic-net
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

networks:
  diagnostic-net:
    driver: bridge
    driver_opts:
      com.docker.network.bridge.name: br-diagnostic-symbiote
      com.docker.network.bridge.enable_ip_masquerade: 'true'
      com.docker.network.bridge.enable_icc: 'true'
      com.docker.network.driver.mtu: 1500

volumes:
  agent_memory:
    driver: local
  model_cache:
    driver: local
  ollama-data:
    driver: local
